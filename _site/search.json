[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Georgie Samaha",
    "section": "",
    "text": "I’m a community-focused bioinformatician, working on making bioinformatics more approachable for all life scientists. I’m the Bioinformatics Group Lead at the Sydney Informatics Hub, University of Sydney, working with Australian BioCommons."
  },
  {
    "objectID": "projects/parabricks.html",
    "href": "projects/parabricks.html",
    "title": "Evaluating optimised genomics workflows",
    "section": "",
    "text": "Genomics-based research is computationally intensive work and we are generating data faster and at a higher scale than ever before. Accelerated computing using specialised hardware is key to addressing these intensive data loads.\nI worked closely with partners from the National Computational Infrastructure (NCI), who were looking to make scalable bioinformatics data processing more accessible at their facilities. We worked with NCI to evaluate the performance of NVIDIA Parabricks software suite at their Gadi HPC and benchmark it against highly optimised CPU-based workflows. GPU-accelerated tools, like Parabricks, are currently rare in bioinformatics but have the capacity to significantly reduce the time and computational resources required for complex data processing like mapping and variant calling. The outcomes of this work includes:\n\nA public biological validation performance evaluation protocol\nA public report summarising our findings\nThe availability of NVIDIA Parabricks license at NCI Gadi HPC"
  },
  {
    "objectID": "projects/hpc.html",
    "href": "projects/hpc.html",
    "title": "Bioinformatics and HPC training",
    "section": "",
    "text": "Bioinformaticians and life scientists are increasingly turning to high performance computing infrastructure and efficient, scalable workflows as their research becomes more data intensive. Accessing and getting the most out of these facilities can be challenging for many of us who have never received formal computational sciences training. This webinar series I designed and delivered with colleagues across national computational infrastructure providers introduces the high-performance computing facilities and services available to Australian researchers and ways to access and use them to do high impact research.\n\nWebinar: Pro tips for scaling bioinformatics workflows for HPC\nWebinar: Where to go when your bioinformatics runs out of compute\nWebinar: High performance bioinformatics: submitting your best NCMAS application\nWebinar: Getting started with mapping and variant calling on the command line"
  },
  {
    "objectID": "projects/burmese.html",
    "href": "projects/burmese.html",
    "title": "Feline models of complex human disease",
    "section": "",
    "text": "Cat breeds can serve as informative natural genetic models of human disease because of their similarity to humans in terms of genetics, anatomy, physiology, and our shared environment. By studying cat breeds with a high prevalence of a hertiable disease, like feline diabetes mellitus (FDM) in Burmese cats, we can gain insights into the underlying genetic mechanisms of the diseases.\nFor this project, we explored the genetic landscape of FDM in a population of Australian and European Burmese cats. We used multiple techniques and technologies to identify regions of disease association and selection in affected cats.\n\nMy role\n\nConceptualised all aspects of the research for this project\nLiased with veterinarians and breeders to collect samples\nExtracted genomic DNA from whole blood and buccal swabs\nProcessed and analysed Illumina genotyping array and whole genome sequencing data\nIdentified candidate genes and variants for FDM\nPerformed and published a literature review and original manuscript\n\n\n\nOutcomes\n\nWorkflow: Probe Remap workflow\nPublication: The Burmese cat as a genetic model of type 2 diabetes in humans\nPublication: Mapping the genetic basis of diabetes mellitus in the Australian Burmese cat (Felis catus)"
  },
  {
    "objectID": "projects/bioimage.html",
    "href": "projects/bioimage.html",
    "title": "Public cloud image for bioinformatics",
    "section": "",
    "text": "For most bioinformatics applications, working at the command-line interface is unavoidable and empowering. The CLI gives users the power to work more efficiently, use scalable computing resources, and work more reproducibly. Learning how to effectively use the CLI environment can be particilarly challenging for life scienctists who don’t receive any formal computer science training.\nTo address the challenges of set up and installation, I worked in partnership with Pawsey Supercomputing Research Center and the National Computational Infrastructure to create a purpose built cloud environment to help researchers working on the command-line. It is called the BioImage and is currently available on Pawsey’s Nimbus cloud platform. We are currently working on making it available on other public research cloud and commercial cloud platforms."
  },
  {
    "objectID": "projects/structuralV.html",
    "href": "projects/structuralV.html",
    "title": "Genomic resources for rare peripheral neuropathies",
    "section": "",
    "text": "Like many other rare and heritable conditions, mapping the causative genetic loci of peripheral neuropathies can be challenging due to a lack of available population-level data and standardised methodologies available to the research community. I have worked closely and collaboratively with the Australian motor neuropathies community to develop reproducible and sensitive protocols for identifying clinically relevant genomic events in patient cohorts and families.\n\nMy role\n\nDesign and implement a protocol for filtering variants under expected modes of inheritance\nDesign and implement a public, sensitive, and reproducible workflow for identifying and annotating structural variation\nIdentify candidate causative genomic events\nLiase and collaborate with bioinformaticians, clinicians, and geneticists to optimise a bioinformatics workflow\n\n\n\nOutcomes\n\nWorkflow: GermlineStructuralV-nf\nResults currently under embargo"
  },
  {
    "objectID": "archive/byod.html",
    "href": "archive/byod.html",
    "title": "Making bioinformatics workflows accessible",
    "section": "",
    "text": "Working at the command line is challenging for life scientists, many of whom have received no formal computer science training. The Australian BioCommons Bring Your Own Data platforms project is focused on providing the life science community with curated workflows, tools, training and support across Australian command line infrastructures.\n\nMy role\n\nWorkflows theme lead\nDeveloped public, scalable, reproducible data processing workflows\nConceptualised national training events focused on the accessibility of bioinformatics workflows at the command-line\nDelivered and facilitated workshops and webinars as a part of the Australian BioCommons training programme\nLiased with and coordinated activites involving partners at various computational infrastructures, service providers, research communities across the country\nAdvocated for the needs and interests of the life science community to national computational infrastructures and service providers\n\n\n\nOutcomes\n\nInstallation and optimisation of bioinformatics workflows across command line infrastructures at NCI, Pawsey, QRIScloud, and the University of Melbourne Research Computing Services\nEnabled 60 high-impact publications\nSupported 11 research groups\nDeveloped 19 public workflows\n1,600 genomes processed at national HPCs\n1,000 transcriptomes processed at national HPCs\nUpskilled 1,000 life scientists\n\n\n\nSkills\n\nData analysis, software engineering, project management, verbal and written communication\nDisciplines: bioinformatics\nPlatforms: HPC, cloud, RStudio\nTools: bash, R, python, PBS, SLURM, git, GitHub, Nextflow, Singularity, Docker, sHPC"
  },
  {
    "objectID": "projects/110dogs.html",
    "href": "projects/110dogs.html",
    "title": "Canine health and population genomics",
    "section": "",
    "text": "This project involved the processing of a large whole genome sequence dataset comprising 113 samples. To process these samples, we developed and applied two highly scalable workflows to realign all samples to a more recent version of the canine reference genome assembly and call short variants (SNVs and indels) across the genome. The scale of the dataset required the use of the National Computational Infrastructure’s Gadi high performance computer.\n\nMy role\n\nDeveloped and integrated processes for non-human samples into an existing public workflow\nRealigned and called short variants at NCI Gadi\nGenerated a large-scale multi-breed database of short variants\nOnboarded and supported researcher in accessing and using NCI Gadi HPC\n\n\n\nOutcomes\n\nPublication: GWAS for Chronic Superficial Keratitis in the Australian Racing Greyhound\nPublication: De-novo and genome-wide meta-analyses identify a risk haplotype for congenital sensorineural deafness in Dalmatian dogs"
  },
  {
    "objectID": "projects/wildcats.html",
    "href": "projects/wildcats.html",
    "title": "Cross-species applications of genomic tools",
    "section": "",
    "text": "While genomics has enabled vast improvements in the quantification of genome-wide diversity and the identification of adaptive and deleterious alleles in model species, wildlife species have not reaped the same benefits. In resource constrained species, alternative genomic approaches that reduce costs and computational resources can be used to inform conservation management. In the absence of species-specific reference genomes, the availability of a reference genome from a closely related species can provide a reliable substrate for performing variant discovery. Domestic cats benefit from high-quality reference genome assemblies and share a high degree of genomic synteny with their wild counterparts. In this project, I evaluated and demonstrated the value of cross-species application of various genomic resources developed for the domesitc cat in the Sumatran tiger, snow leopard and cheetah.\n\nMy role\n\nConceptualised all aspects of the research for this project\nLiased with veterinarians and zoo managers to collect samples\nExtracted genomic DNA from whole blood and buccal swabs\nProcessed and analysed whole genome sequencing data\nPerformed in silico simulation of genotyping array and reduced representation sequencing datasets\nPerformed and published a literature review and original manuscript\n\n\n\nOutcomes\n\nPublication: Exploiting genomic synteny in Felidae: cross-species genome alignments and SNV discovery can aid conservation management\nOther results currently under embargo"
  },
  {
    "objectID": "projects/cancer.html",
    "href": "projects/cancer.html",
    "title": "Precision diagnostics in thyroid cancer",
    "section": "",
    "text": "Whole-genome profiling of somatic mutations allows researchers to develop new insights into the underlying causes of cancers and develop new treatments and prevention strategies. However, genetic profiling of poorly understood cancers can be challenging due to the complexity and heterogeneity of somatic mutations across patient populations, and lacking population-level data. Best practice bioinformatics workflows that provide a standardised approach to somatic mutation identification and annotation can address these challenges and provide clinicians with viable treatment targets.\n\nMy role\n\nIdentified and implemented best practice bioinformatic tools and public datasets\nImplemented 2 best pratice workflows to provide patient reports and identify short and structural variants in a cohort of thyroid cancer patients\nIdentified candidate genes for poorly differentiated thyroid cancer\n\n\n\nOutcomes\n\nWorkflow under development\nResults under embargo"
  },
  {
    "objectID": "projects/nextflow.html",
    "href": "projects/nextflow.html",
    "title": "Flattening the Nextflow learning curve",
    "section": "",
    "text": "Workflow frameworks, like Nextflow, have recently emerged as solutions to the challenges posed by bioinformatics pipelines. Bioinformatics data processing typically comprises many individual steps that accept and output varying file formats, and require the use of multiple coding languages and pieces of software. While Nextflow offers a nice solution for creating reproducible, portable workflows that are easy to run, it comes at the cost of a steep learning curve. Nextflow’s users need to learn yet another Domain-Specific Language (DSL) and a new and foreign programming paradigm in order to get the most out of it.\nAs a part of the Australian BioCommons Bring Your Own Data platforms project, we focused on Nextflow over other workflow frameworks in our workflow development activities, developer support, and training programme due to its growing popularity in the community. The outcomes of this work includes:\n\nMy participation in round 3 of the nf-core mentorship programme\nThe development of institutional configuration files for Australian national HPC infrastructure (Gadi, Setonix, Nimbus)\nThe delivery of a national online workshop focused on customising nf-core workflows in partnership with Seqera Labs\nThe development of a simple Nextflow workflow template\nThe ongoing development of an automated configuration builder tool"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Georgie Samaha",
    "section": "",
    "text": "I work at the Sydney Informatics Hub, University of Sydney, and Australian BioCommons, directly supporting Australian researchers by developing open-source tools and solutions and consulting on reproducible research practices and best-practice bioinformatics.\nI am the product owner for the Australian BioCommons’ BioCLI and University of Sydney’s Sydney Research Cloud projects. My interest lies in making computing infrastructure and bioinformatics methods more approachable, particularly for life scientists who are new to compute-based research.\nI completed a PhD in mammalian genomics under the supervision of Associate Professor Bianca Waud and Professor Claire Wade. My research focused on applying genomic technologies to understand the genetic basis of complex traits in wild felids and domestic cats."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Georgie Samaha",
    "section": "",
    "text": "Becoming a good bioinformatician is all about practice. You need to get your hands dirty, make mistakes, and learn from them. I use this blog to track my learnings and mistakes.\n\n\n\n\n\n\n\n\n\n\n\n\nExperimental data analysis in cohorts\n\n\n\n\n\n\n\n\n\n\n\nFile formats in bioinformatics: BAM\n\n\n\n\n\n\n\n\n\n\n\nFile formats in bioinformatics: FASTA\n\n\n\n\n\n\n\n\n\n\n\nFile formats in bioinformatics: FASTQ\n\n\n\n\n\n\n\n\n\n\n\nFile formats in bioinformatics: PDB\n\n\n\n\n\n\n\n\n\n\n\nFile formats in bioinformatics: VCF\n\n\n\n\n\n\n\n\n\n\n\nStructural biology for a bioinformatician\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/file-formats.html",
    "href": "blog/file-formats.html",
    "title": "File formats in bioinformatics: FASTA",
    "section": "",
    "text": "Learn from my mistakes\n\n\n\nI’ve made lots of mistakes in my time doing bioinformatics, many of them have come down to rushing into analysis without fully understanding the file formats I was working with.\n\n\nThere are many and varied file formats in bioinformatics. Many of them are text-based and can technically be opened in a text editor but are often so large they cannot be opened without crashing your machine. Other file types are binary and cannot be opened in a text editor at all. These days, most tools will handle standard file formats but sometimes you will need to do some manual manipulation to get your data into the right format for a particular tool.\nHere, I explain some common file formats and things to consider when working with them. These things are very easy to forget unless you’re working with these file regularly. Others have explained this better than I can, so I will link to other resources where possible.\n\n\nLets start simple. Lots of people’s first introduction to bioinformatics will involve a FASTA file.\n\n\n1. Reference genomes and transcriptomes\n2. Databases for sequence searches\n3. Phylogenetic multiple sequence alignments\n\n\n\nBiological sequences (DNA, RNA or protein) and some metadata. Each entry has 2 parts:\n\nHeader line starting with &gt;\nSequence line(s)\n\nConsider this example of a protein FASTA entry:\n&gt;NP_001036025.2 TYRP1 [organism=Felis catus] [GeneID=554339]\nMKAHKFLSLGYIVLPLLCSPQTWAQFPRQCATVEALRNGVCCPDLSPLSGPGTDRCGSSSGRGRCEAVTA\nDSRPHSLHYPHDGRDDREAWPTRFFNRTCRCNGNFSGHNCGTCRPGWKGAACDQRVLIVRRNLLDLSAEE\nKNHLVQALHLAKRTMHPQFVIATRRSEEILGPDGNTPQFENISIYNYFVWTHYYSVKKTFLGPGQESFGE\nVDFSHEGPAFLTWHRYHLLQLERDMQEMLQDPSFSLPYWNFATGKNICDICTDDLMGSRSNFDPTLISLN\nSVFSQWRVVCESLEDYDTLGTLCNSTEGGPIRRNPAGNVARPMVQRLPEPQDVAQCLEVGLFDTPPFYSN\nSTNSFRNTVEGYSDPTGKYDPAIRSLHNLAHLFLNGTGGQTHLSPNDPIFVLLHTFTDAVFDEWLRRYNA\nDVSTFPLENAPIGHNRQYNMVPFWPPVTNIEMFVTAPDNLGYTYEVQWPSRNFSISELVTIGVVAALSLV\nAVIFAGASCMIRARSNMDEAHQPLLTDQYQHYAEEYEKMHNPNQSMV\nFASTA files don’t have a strict extension requirement but you’ll often see them named .fasta, .fa, .fna, or .faa. Most tools will accept any extension as long as the file is formatted correctly.\n\n\n\n\n\n\n\n\nExtension\nTypical usage\nExample source\n\n\n\n\n.fasta\nMost common extension\nNCBI RefSeq genome assemblies\n\n\n.fa\nShort form, often used for genomes\nEnsembl genome FASTAs (e.g. Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz)\n\n\n.faa\n“FASTA amino acids” (protein sequences)\nUniProt/RefSeq protein databases\n\n\n.fna\n“FASTA nucleic acids” (DNA/RNA)\nNCBI RefSeq nucleotide FASTAs (e.g. bacteria.fna.gz)\n\n\n\n\n\n\nCount the total number of sequences:\ngrep -c \"^&gt;\" my.fasta\nExtract the headers:\ngrep \"^&gt;\" my.fasta\nGet the lengths of each sequence:\nawk '/^&gt;/ {if (seqlen){print seqlen}; seqlen=0; next} {seqlen += length($0)} END{print seqlen}' my.fasta  \n\n\n\n\nFASTA wiki\nFASTA file standard\nEdit FASTA files reliably"
  },
  {
    "objectID": "blog/file-formats.html#fasta",
    "href": "blog/file-formats.html#fasta",
    "title": "File formats in bioinformatics: FASTA",
    "section": "",
    "text": "Lets start simple. Lots of people’s first introduction to bioinformatics will involve a FASTA file.\n\n\n1. Reference genomes and transcriptomes\n2. Databases for sequence searches\n3. Phylogenetic multiple sequence alignments\n\n\n\nBiological sequences (DNA, RNA or protein) and some metadata. Each entry has 2 parts:\n\nHeader line starting with &gt;\nSequence line(s)\n\nConsider this example of a protein FASTA entry:\n&gt;NP_001036025.2 TYRP1 [organism=Felis catus] [GeneID=554339]\nMKAHKFLSLGYIVLPLLCSPQTWAQFPRQCATVEALRNGVCCPDLSPLSGPGTDRCGSSSGRGRCEAVTA\nDSRPHSLHYPHDGRDDREAWPTRFFNRTCRCNGNFSGHNCGTCRPGWKGAACDQRVLIVRRNLLDLSAEE\nKNHLVQALHLAKRTMHPQFVIATRRSEEILGPDGNTPQFENISIYNYFVWTHYYSVKKTFLGPGQESFGE\nVDFSHEGPAFLTWHRYHLLQLERDMQEMLQDPSFSLPYWNFATGKNICDICTDDLMGSRSNFDPTLISLN\nSVFSQWRVVCESLEDYDTLGTLCNSTEGGPIRRNPAGNVARPMVQRLPEPQDVAQCLEVGLFDTPPFYSN\nSTNSFRNTVEGYSDPTGKYDPAIRSLHNLAHLFLNGTGGQTHLSPNDPIFVLLHTFTDAVFDEWLRRYNA\nDVSTFPLENAPIGHNRQYNMVPFWPPVTNIEMFVTAPDNLGYTYEVQWPSRNFSISELVTIGVVAALSLV\nAVIFAGASCMIRARSNMDEAHQPLLTDQYQHYAEEYEKMHNPNQSMV\nFASTA files don’t have a strict extension requirement but you’ll often see them named .fasta, .fa, .fna, or .faa. Most tools will accept any extension as long as the file is formatted correctly.\n\n\n\n\n\n\n\n\nExtension\nTypical usage\nExample source\n\n\n\n\n.fasta\nMost common extension\nNCBI RefSeq genome assemblies\n\n\n.fa\nShort form, often used for genomes\nEnsembl genome FASTAs (e.g. Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz)\n\n\n.faa\n“FASTA amino acids” (protein sequences)\nUniProt/RefSeq protein databases\n\n\n.fna\n“FASTA nucleic acids” (DNA/RNA)\nNCBI RefSeq nucleotide FASTAs (e.g. bacteria.fna.gz)\n\n\n\n\n\n\nCount the total number of sequences:\ngrep -c \"^&gt;\" my.fasta\nExtract the headers:\ngrep \"^&gt;\" my.fasta\nGet the lengths of each sequence:\nawk '/^&gt;/ {if (seqlen){print seqlen}; seqlen=0; next} {seqlen += length($0)} END{print seqlen}' my.fasta  \n\n\n\n\nFASTA wiki\nFASTA file standard\nEdit FASTA files reliably"
  },
  {
    "objectID": "blog/fastq.html",
    "href": "blog/fastq.html",
    "title": "File formats in bioinformatics: FASTQ",
    "section": "",
    "text": "File formats in bioinformatics: FASTQ\n\n\n\n\n\n\nLearn from my mistakes\n\n\n\nI’ve made lots of mistakes in my time doing bioinformatics, many of them have come down to rushing into analysis without fully understanding the file formats I was working with.\n\n\nThere are many and varied file formats in bioinformatics. Many of them are text-based and can technically be opened in a text editor but are often so large they cannot be opened without crashing your machine. Other file types are binary and cannot be opened in a text editor at all. These days, most tools will handle standard file formats but sometimes you will need to do some manual manipulation to get your data into the right format for a particular tool.\nHere, I explain some common file formats and things to consider when working with them. These things are very easy to forget unless you’re working with these file regularly. Others have explained this better than I can, so I will link to other resources where possible."
  },
  {
    "objectID": "blog/bam.html",
    "href": "blog/bam.html",
    "title": "File formats in bioinformatics: BAM",
    "section": "",
    "text": "File formats in bioinformatics: BAM\n\n\n\n\n\n\nLearn from my mistakes\n\n\n\nI’ve made lots of mistakes in my time doing bioinformatics, many of them have come down to rushing into analysis without fully understanding the file formats I was working with.\n\n\nThere are many and varied file formats in bioinformatics. Many of them are text-based and can technically be opened in a text editor but are often so large they cannot be opened without crashing your machine. Other file types are binary and cannot be opened in a text editor at all. These days, most tools will handle standard file formats but sometimes you will need to do some manual manipulation to get your data into the right format for a particular tool.\nHere, I explain some common file formats and things to consider when working with them. These things are very easy to forget unless you’re working with these file regularly. Others have explained this better than I can, so I will link to other resources where possible."
  },
  {
    "objectID": "blog/fasta.html",
    "href": "blog/fasta.html",
    "title": "File formats in bioinformatics: FASTA",
    "section": "",
    "text": "Learn from my mistakes\n\n\n\nI’ve made lots of mistakes in my time doing bioinformatics, many of them have come down to rushing into analysis without fully understanding the file formats I was working with.\n\n\nThere are many and varied file formats in bioinformatics. Many of them are text-based and can technically be opened in a text editor but are often so large they cannot be opened without crashing your machine. Other file types are binary and cannot be opened in a text editor at all. These days, most tools will handle standard file formats but sometimes you will need to do some manual manipulation to get your data into the right format for a particular tool.\nHere, I explain some common file formats and things to consider when working with them. These things are very easy to forget unless you’re working with these file regularly. Others have explained this better than I can, so I will link to other resources where possible.\n\n\nLets start simple. Lots of people’s first introduction to bioinformatics will involve a FASTA file.\n\n\n1. Reference genomes and transcriptomes\n2. Databases for sequence searches\n3. Phylogenetic multiple sequence alignments\n\n\n\nBiological sequences (DNA, RNA or protein) and some metadata. Each entry has 2 parts:\n\nHeader line starting with &gt;\nSequence line(s)\n\nConsider this example of a protein FASTA entry:\n&gt;NP_001036025.2 TYRP1 [organism=Felis catus] [GeneID=554339]\nMKAHKFLSLGYIVLPLLCSPQTWAQFPRQCATVEALRNGVCCPDLSPLSGPGTDRCGSSSGRGRCEAVTA\nDSRPHSLHYPHDGRDDREAWPTRFFNRTCRCNGNFSGHNCGTCRPGWKGAACDQRVLIVRRNLLDLSAEE\nKNHLVQALHLAKRTMHPQFVIATRRSEEILGPDGNTPQFENISIYNYFVWTHYYSVKKTFLGPGQESFGE\nVDFSHEGPAFLTWHRYHLLQLERDMQEMLQDPSFSLPYWNFATGKNICDICTDDLMGSRSNFDPTLISLN\nSVFSQWRVVCESLEDYDTLGTLCNSTEGGPIRRNPAGNVARPMVQRLPEPQDVAQCLEVGLFDTPPFYSN\nSTNSFRNTVEGYSDPTGKYDPAIRSLHNLAHLFLNGTGGQTHLSPNDPIFVLLHTFTDAVFDEWLRRYNA\nDVSTFPLENAPIGHNRQYNMVPFWPPVTNIEMFVTAPDNLGYTYEVQWPSRNFSISELVTIGVVAALSLV\nAVIFAGASCMIRARSNMDEAHQPLLTDQYQHYAEEYEKMHNPNQSMV\nFASTA files don’t have a strict extension requirement but you’ll often see them named .fasta, .fa, .fna, or .faa. Most tools will accept any extension as long as the file is formatted correctly.\n\n\n\n\n\n\n\n\nExtension\nTypical usage\nExample source\n\n\n\n\n.fasta\nMost common extension\nNCBI RefSeq genome assemblies\n\n\n.fa\nShort form, often used for genomes\nEnsembl genome FASTAs\n\n\n.faa\n“FASTA amino acids” (protein sequences)\nUniProt/RefSeq protein databases\n\n\n.fna\n“FASTA nucleic acids” (DNA/RNA)\nNCBI RefSeq nucleotide FASTAs\n\n\n\n\n\n\nCount the total number of sequences:\ngrep -c \"^&gt;\" my.fasta\nExtract the headers:\ngrep \"^&gt;\" my.fasta\nGet the lengths of each sequence:\nawk '/^&gt;/ {if (seqlen){print seqlen}; seqlen=0; next} {seqlen += length($0)} END{print seqlen}' my.fasta  \n\n\n\n\nFASTA wiki\nFASTA file standard\nEdit FASTA files reliably"
  },
  {
    "objectID": "blog/fasta.html#fasta",
    "href": "blog/fasta.html#fasta",
    "title": "File formats in bioinformatics: FASTA",
    "section": "",
    "text": "Lets start simple. Lots of people’s first introduction to bioinformatics will involve a FASTA file.\n\n\n1. Reference genomes and transcriptomes\n2. Databases for sequence searches\n3. Phylogenetic multiple sequence alignments\n\n\n\nBiological sequences (DNA, RNA or protein) and some metadata. Each entry has 2 parts:\n\nHeader line starting with &gt;\nSequence line(s)\n\nConsider this example of a protein FASTA entry:\n&gt;NP_001036025.2 TYRP1 [organism=Felis catus] [GeneID=554339]\nMKAHKFLSLGYIVLPLLCSPQTWAQFPRQCATVEALRNGVCCPDLSPLSGPGTDRCGSSSGRGRCEAVTA\nDSRPHSLHYPHDGRDDREAWPTRFFNRTCRCNGNFSGHNCGTCRPGWKGAACDQRVLIVRRNLLDLSAEE\nKNHLVQALHLAKRTMHPQFVIATRRSEEILGPDGNTPQFENISIYNYFVWTHYYSVKKTFLGPGQESFGE\nVDFSHEGPAFLTWHRYHLLQLERDMQEMLQDPSFSLPYWNFATGKNICDICTDDLMGSRSNFDPTLISLN\nSVFSQWRVVCESLEDYDTLGTLCNSTEGGPIRRNPAGNVARPMVQRLPEPQDVAQCLEVGLFDTPPFYSN\nSTNSFRNTVEGYSDPTGKYDPAIRSLHNLAHLFLNGTGGQTHLSPNDPIFVLLHTFTDAVFDEWLRRYNA\nDVSTFPLENAPIGHNRQYNMVPFWPPVTNIEMFVTAPDNLGYTYEVQWPSRNFSISELVTIGVVAALSLV\nAVIFAGASCMIRARSNMDEAHQPLLTDQYQHYAEEYEKMHNPNQSMV\nFASTA files don’t have a strict extension requirement but you’ll often see them named .fasta, .fa, .fna, or .faa. Most tools will accept any extension as long as the file is formatted correctly.\n\n\n\n\n\n\n\n\nExtension\nTypical usage\nExample source\n\n\n\n\n.fasta\nMost common extension\nNCBI RefSeq genome assemblies\n\n\n.fa\nShort form, often used for genomes\nEnsembl genome FASTAs\n\n\n.faa\n“FASTA amino acids” (protein sequences)\nUniProt/RefSeq protein databases\n\n\n.fna\n“FASTA nucleic acids” (DNA/RNA)\nNCBI RefSeq nucleotide FASTAs\n\n\n\n\n\n\nCount the total number of sequences:\ngrep -c \"^&gt;\" my.fasta\nExtract the headers:\ngrep \"^&gt;\" my.fasta\nGet the lengths of each sequence:\nawk '/^&gt;/ {if (seqlen){print seqlen}; seqlen=0; next} {seqlen += length($0)} END{print seqlen}' my.fasta  \n\n\n\n\nFASTA wiki\nFASTA file standard\nEdit FASTA files reliably"
  },
  {
    "objectID": "blog/structural-bio.html",
    "href": "blog/structural-bio.html",
    "title": "Structural biology for a bioinformatician",
    "section": "",
    "text": "Structural biology for a bioinformatician"
  },
  {
    "objectID": "blog/cohort-eda.html",
    "href": "blog/cohort-eda.html",
    "title": "Experimental data analysis in cohorts",
    "section": "",
    "text": "Experimental data analysis in cohorts"
  },
  {
    "objectID": "blog/pdb.html",
    "href": "blog/pdb.html",
    "title": "File formats in bioinformatics: PDB",
    "section": "",
    "text": "Learn from my mistakes\n\n\n\nI’ve made lots of mistakes in my time doing bioinformatics, many of them have come down to rushing into analysis without fully understanding the file formats I was working with.\n\n\nThere are many and varied file formats in bioinformatics. Many of them are text-based and can technically be opened in a text editor but are often so large they cannot be opened without crashing your machine. Other file types are binary and cannot be opened in a text editor at all. These days, most tools will handle standard file formats but sometimes you will need to do some manual manipulation to get your data into the right format for a particular tool.\nHere, I explain some common file formats and things to consider when working with them. These things are very easy to forget unless you’re working with these file regularly. Others have explained this better than I can, so I will link to other resources where possible."
  },
  {
    "objectID": "blog/vcf.html",
    "href": "blog/vcf.html",
    "title": "File formats in bioinformatics: VCF",
    "section": "",
    "text": "File formats in bioinformatics: VCF"
  }
]