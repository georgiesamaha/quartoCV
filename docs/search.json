[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Georgie Samaha",
    "section": "",
    "text": "Becoming a good bioinformatician is all about practice. You need to get your hands dirty, make mistakes, and learn from them. I use this blog to track my learnings and mistakes.\n\n\n\n\n\n\n\n\n\n\n\n\nBash essentials: debugging\n\n\n\n\n\n\n\n\n\n\n\nFile formats in bioinformatics: FASTA\n\n\n\n\n\n\n\n\n\n\n\nFile formats in bioinformatics: FASTQ\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/fasta.html",
    "href": "blog/fasta.html",
    "title": "File formats in bioinformatics: FASTA",
    "section": "",
    "text": "Learn from my mistakes\n\n\n\nI’ve made lots of mistakes in my time doing bioinformatics, many of them have come down to rushing into analysis without fully understanding the file formats I was working with.\n\n\nThere are many and varied file formats in bioinformatics. Many of them are text-based and can technically be opened in a text editor but are often so large they cannot be opened without crashing your machine. Other file types are binary and cannot be opened in a text editor at all. These days, most tools will handle standard file formats but sometimes you will need to do some manual manipulation to get your data into the right format for a particular tool.\nHere, I explain some common file formats and things to consider when working with them. These things are very easy to forget unless you’re working with these file regularly. Others have explained this better than I can, so I will link to other resources where possible.\n\n\nLets start simple. Lots of people’s first introduction to bioinformatics will involve working with some sequence in a FASTA file.\n\n\nBiological sequences (DNA, RNA or protein) and some metadata. Each entry has 2 parts:\n\nHeader line starting with &gt;\nSequence line(s)\n\nEverything after the &gt; on the header line is free text, many projects use this to store metadata about the sequence. The exact format of this metadata can vary between databases and tools, but it often includes an identifier, a description, and sometimes additional information like the organism name or gene name.\nConsider this example of a protein FASTA entry:\n&gt;NP_001036025.2 TYRP1 [organism=Felis catus] [GeneID=554339]\nMKAHKFLSLGYIVLPLLCSPQTWAQFPRQCATVEALRNGVCCPDLSPLSGPGTDRCGSSSGRGRCEAVTA\nDSRPHSLHYPHDGRDDREAWPTRFFNRTCRCNGNFSGHNCGTCRPGWKGAACDQRVLIVRRNLLDLSAEE\nKNHLVQALHLAKRTMHPQFVIATRRSEEILGPDGNTPQFENISIYNYFVWTHYYSVKKTFLGPGQESFGE\nVDFSHEGPAFLTWHRYHLLQLERDMQEMLQDPSFSLPYWNFATGKNICDICTDDLMGSRSNFDPTLISLN\nSVFSQWRVVCESLEDYDTLGTLCNSTEGGPIRRNPAGNVARPMVQRLPEPQDVAQCLEVGLFDTPPFYSN\nSTNSFRNTVEGYSDPTGKYDPAIRSLHNLAHLFLNGTGGQTHLSPNDPIFVLLHTFTDAVFDEWLRRYNA\nDVSTFPLENAPIGHNRQYNMVPFWPPVTNIEMFVTAPDNLGYTYEVQWPSRNFSISELVTIGVVAALSLV\nAVIFAGASCMIRARSNMDEAHQPLLTDQYQHYAEEYEKMHNPNQSMV\nFASTA files don’t have a strict extension requirement but you’ll often see them named .fasta, .fa, .fna, or .faa. Most tools will accept any extension as long as the file is formatted correctly.\n\n\n\n\n\n\n\n\nExtension\nTypical usage\nExample source\n\n\n\n\n.fasta\nMost common extension\nNCBI RefSeq genome assemblies\n\n\n.fa\nShort form, often used for genomes\nEnsembl genome FASTAs\n\n\n.faa\n“FASTA amino acids” (protein sequences)\nUniProt/RefSeq protein databases\n\n\n.fna\n“FASTA nucleic acids” (DNA/RNA)\nNCBI RefSeq nucleotide FASTAs\n\n\n\nFASTA files can contain one or many sequences. When a FASTA file contains multiple sequences, each sequence entry starts with its own header line beginning with the &gt; character, followed by the corresponding sequence lines:\n&gt;sp|P57073|SOX8_HUMAN Transcription factor SOX-8 OS=Homo sapiens OX=9606 GN=SOX8 PE=1 SV=1\nMLDMSEARSQPPCSPSGTASSMSHVEDSDSDAPPSPAGSEGLGRAGVAVGGARGDPAEAA\nDERFPACIRDAVSQVLKGYDWSLVPMPVRGGGGGALKAKPHVKRPMNAFMVWAQAARRKL\nADQYPHLHNAELSKTLGKLWRLLSESEKRPFVEEAERLRVQHKKDHPDYKYQPRRRKSAK\nAGHSDSDSGAELGPHPGGGAVYKAEAGLGDGHHHGDHTGQTHGPPTPPTTPKTELQQAGA\nKPELKLEGRRPVDSGRQNIDFSNVDISELSSEVMGTMDAFDVHEFDQYLPLGGPAPPEPG\nQAYGGAYFHAGASPVWAHKSAPSASASPTETGPPRPHIKTEQPSPGHYGDQPRGSPDYGS\nCSGQSSATPAAPAGPFAGSQGDYGDLQASSYYGAYPGYAPGLYQYPCFHSPRRPYASPLL\nNGLALPPAHSPTSHWDQPVYTTLTRP\n&gt;SOX8_p.Leu102fs\nMLDMSEARSQPPCSPSGTASSMSHVEDSDSDAPPSPAGSEGLGRAGVAVGGARGDPAEAA\nDERFPACIRDAVSQVLKGYDWSLVPMPVRGGGGGALKAKPHVKRLLTRSRRL* \n\n\n\n\n\n\nA note on line wrapping\n\n\n\nThe sequence part of a FASTA can be wrapped at a fixed width (commonly 60 or 80 characters per line) or left unwrapped as one long line. Most tools don’t mind either style, but remember that line breaks are not biologically meaningful.\n\n\n\n\n\n1. Reference genomes and transcriptomes\nLarge FASTA files containing the complete DNA or RNA sequence of an organism are often the starting point for nearly every reference-based genomic analysis.\nUnless you’re working with a non-model organism without a publicly available reference assembly, you will be able to find these FASTA files for your organism of interest in a public database such as NCBI, Ensembl, or UCSC.\nGiven the size of reference assemblies, tools often require you to index them before use. This is a one-time operation that creates additional files to allow the software to quickly look-up specific parts of the reference sequence. The exact command to run and index files required will vary between tools.\n\nEnsembl FTP download site\nNCBI genome download portal\nUCSC genome download site\n\n2. Databases for sequence searches\nThi is likely the most common way people first use a FASTA file. Sequence comparison tools (e.g. BLAST and HMMER) require FASTA input for both the query sequence (the sequence you want to investigate) and the reference database (the collection of known sequences to compare against).\nYou may use reference sequences for a specific gene or protein, create a database of multiple sequences, or create a custom sequence that includes some change to a wild type sequence (e.g. a mutation).\n3. Phylogenetic multiple sequence alignments\nIf you’re studying the evolutionary relationships between sequences, you might use a FASTA file to store a multiple sequence alignment (MSA). MSAs are used to identify conserved regions, infer evolutionary relationships, and construct phylogenetic trees.\nThere are some specialised formats for the application of FASTA files in this context. For example, gaps are represented with the dash (-) character to indicate insertions or deletions in the alignment. Sequences may be padded with gaps so they have equal length and residues may be uppercase or lowercase to indicate confidence in the alignment.\n\nMSA wiki\n\n\n\n\nHave a go at this tutorial on Sandbox.bio for wrangling FASTA files.\nCount the total number of sequences:\ngrep -c \"^&gt;\" my.fasta\nExtract the headers:\ngrep \"^&gt;\" my.fasta\nGet the lengths of each sequence:\nawk '/^&gt;/ {if (seqlen){print seqlen}; seqlen=0; next} {seqlen += length($0)} END{print seqlen}' my.fasta  \nSplit a multi-sequence FASTA into individual FASTA files:\nawk '/^&gt;/{s=++d\".fa\"} {print &gt; s}' my.fa\n\n\n\n\nFASTA wiki\nFASTA file standard\nSeqtk for parsing FASTA files\nEdit FASTA files reliably with reform\nIUPAC codes for nucleotides and amino acids\nSandbox.bio FASTA tutorial"
  },
  {
    "objectID": "blog/fasta.html#fasta",
    "href": "blog/fasta.html#fasta",
    "title": "File formats in bioinformatics: FASTA",
    "section": "",
    "text": "Lets start simple. Lots of people’s first introduction to bioinformatics will involve working with some sequence in a FASTA file.\n\n\nBiological sequences (DNA, RNA or protein) and some metadata. Each entry has 2 parts:\n\nHeader line starting with &gt;\nSequence line(s)\n\nEverything after the &gt; on the header line is free text, many projects use this to store metadata about the sequence. The exact format of this metadata can vary between databases and tools, but it often includes an identifier, a description, and sometimes additional information like the organism name or gene name.\nConsider this example of a protein FASTA entry:\n&gt;NP_001036025.2 TYRP1 [organism=Felis catus] [GeneID=554339]\nMKAHKFLSLGYIVLPLLCSPQTWAQFPRQCATVEALRNGVCCPDLSPLSGPGTDRCGSSSGRGRCEAVTA\nDSRPHSLHYPHDGRDDREAWPTRFFNRTCRCNGNFSGHNCGTCRPGWKGAACDQRVLIVRRNLLDLSAEE\nKNHLVQALHLAKRTMHPQFVIATRRSEEILGPDGNTPQFENISIYNYFVWTHYYSVKKTFLGPGQESFGE\nVDFSHEGPAFLTWHRYHLLQLERDMQEMLQDPSFSLPYWNFATGKNICDICTDDLMGSRSNFDPTLISLN\nSVFSQWRVVCESLEDYDTLGTLCNSTEGGPIRRNPAGNVARPMVQRLPEPQDVAQCLEVGLFDTPPFYSN\nSTNSFRNTVEGYSDPTGKYDPAIRSLHNLAHLFLNGTGGQTHLSPNDPIFVLLHTFTDAVFDEWLRRYNA\nDVSTFPLENAPIGHNRQYNMVPFWPPVTNIEMFVTAPDNLGYTYEVQWPSRNFSISELVTIGVVAALSLV\nAVIFAGASCMIRARSNMDEAHQPLLTDQYQHYAEEYEKMHNPNQSMV\nFASTA files don’t have a strict extension requirement but you’ll often see them named .fasta, .fa, .fna, or .faa. Most tools will accept any extension as long as the file is formatted correctly.\n\n\n\n\n\n\n\n\nExtension\nTypical usage\nExample source\n\n\n\n\n.fasta\nMost common extension\nNCBI RefSeq genome assemblies\n\n\n.fa\nShort form, often used for genomes\nEnsembl genome FASTAs\n\n\n.faa\n“FASTA amino acids” (protein sequences)\nUniProt/RefSeq protein databases\n\n\n.fna\n“FASTA nucleic acids” (DNA/RNA)\nNCBI RefSeq nucleotide FASTAs\n\n\n\nFASTA files can contain one or many sequences. When a FASTA file contains multiple sequences, each sequence entry starts with its own header line beginning with the &gt; character, followed by the corresponding sequence lines:\n&gt;sp|P57073|SOX8_HUMAN Transcription factor SOX-8 OS=Homo sapiens OX=9606 GN=SOX8 PE=1 SV=1\nMLDMSEARSQPPCSPSGTASSMSHVEDSDSDAPPSPAGSEGLGRAGVAVGGARGDPAEAA\nDERFPACIRDAVSQVLKGYDWSLVPMPVRGGGGGALKAKPHVKRPMNAFMVWAQAARRKL\nADQYPHLHNAELSKTLGKLWRLLSESEKRPFVEEAERLRVQHKKDHPDYKYQPRRRKSAK\nAGHSDSDSGAELGPHPGGGAVYKAEAGLGDGHHHGDHTGQTHGPPTPPTTPKTELQQAGA\nKPELKLEGRRPVDSGRQNIDFSNVDISELSSEVMGTMDAFDVHEFDQYLPLGGPAPPEPG\nQAYGGAYFHAGASPVWAHKSAPSASASPTETGPPRPHIKTEQPSPGHYGDQPRGSPDYGS\nCSGQSSATPAAPAGPFAGSQGDYGDLQASSYYGAYPGYAPGLYQYPCFHSPRRPYASPLL\nNGLALPPAHSPTSHWDQPVYTTLTRP\n&gt;SOX8_p.Leu102fs\nMLDMSEARSQPPCSPSGTASSMSHVEDSDSDAPPSPAGSEGLGRAGVAVGGARGDPAEAA\nDERFPACIRDAVSQVLKGYDWSLVPMPVRGGGGGALKAKPHVKRLLTRSRRL* \n\n\n\n\n\n\nA note on line wrapping\n\n\n\nThe sequence part of a FASTA can be wrapped at a fixed width (commonly 60 or 80 characters per line) or left unwrapped as one long line. Most tools don’t mind either style, but remember that line breaks are not biologically meaningful.\n\n\n\n\n\n1. Reference genomes and transcriptomes\nLarge FASTA files containing the complete DNA or RNA sequence of an organism are often the starting point for nearly every reference-based genomic analysis.\nUnless you’re working with a non-model organism without a publicly available reference assembly, you will be able to find these FASTA files for your organism of interest in a public database such as NCBI, Ensembl, or UCSC.\nGiven the size of reference assemblies, tools often require you to index them before use. This is a one-time operation that creates additional files to allow the software to quickly look-up specific parts of the reference sequence. The exact command to run and index files required will vary between tools.\n\nEnsembl FTP download site\nNCBI genome download portal\nUCSC genome download site\n\n2. Databases for sequence searches\nThi is likely the most common way people first use a FASTA file. Sequence comparison tools (e.g. BLAST and HMMER) require FASTA input for both the query sequence (the sequence you want to investigate) and the reference database (the collection of known sequences to compare against).\nYou may use reference sequences for a specific gene or protein, create a database of multiple sequences, or create a custom sequence that includes some change to a wild type sequence (e.g. a mutation).\n3. Phylogenetic multiple sequence alignments\nIf you’re studying the evolutionary relationships between sequences, you might use a FASTA file to store a multiple sequence alignment (MSA). MSAs are used to identify conserved regions, infer evolutionary relationships, and construct phylogenetic trees.\nThere are some specialised formats for the application of FASTA files in this context. For example, gaps are represented with the dash (-) character to indicate insertions or deletions in the alignment. Sequences may be padded with gaps so they have equal length and residues may be uppercase or lowercase to indicate confidence in the alignment.\n\nMSA wiki\n\n\n\n\nHave a go at this tutorial on Sandbox.bio for wrangling FASTA files.\nCount the total number of sequences:\ngrep -c \"^&gt;\" my.fasta\nExtract the headers:\ngrep \"^&gt;\" my.fasta\nGet the lengths of each sequence:\nawk '/^&gt;/ {if (seqlen){print seqlen}; seqlen=0; next} {seqlen += length($0)} END{print seqlen}' my.fasta  \nSplit a multi-sequence FASTA into individual FASTA files:\nawk '/^&gt;/{s=++d\".fa\"} {print &gt; s}' my.fa\n\n\n\n\nFASTA wiki\nFASTA file standard\nSeqtk for parsing FASTA files\nEdit FASTA files reliably with reform\nIUPAC codes for nucleotides and amino acids\nSandbox.bio FASTA tutorial"
  },
  {
    "objectID": "blog/bash.html",
    "href": "blog/bash.html",
    "title": "Bash essentials: debugging",
    "section": "",
    "text": "Bash reigns supreme in the Unix shell, don’t let the snobs convince you it isn’t worth learning some basics if you’re planning to work in the Unix shell and/or on an HPC. It is an approachable swiss army knife, especially in the context of research computing.\nUnfortunately, bash doesn’t naturally handle errors very well. So, it is essential to include some error handling to ensure your scripts fail well when they encounter an error and you can easily tend to the source of those errors. Let’s delve into some useful techniques:\n\n\nLet’s force bash to behave in a way that eliminates the chances of some subtle bugs from the outset by starting our script with:\n#!/bin/bash\nset -eou pipefail\nYou can use set to change the behaviour of the shell and control script execution. By incorporating this set directive above, you’re doing the following:\n\nset -e mandates immediate script termination upon any command failure\nset -u treats references to undefined variables as errors which helps minimise the likelihood of subtle bugs caused by inadvertent variable omission\nset -o pipefail ensures pipeline errors aren’t masked. If any command in a pipeline fails,\n\nRun the scripts below as is, and then with set commands hashed out. Note the execution of the echo command after the failed commands with/without set.\n\n\nThis enables the errexit option which causes the shell to fail if a command returns a non-zero exit status.\n#!/bin/bash\nset -e\n\n# List the contents of a directory that doesn't exist\nls fake_directory\n\n# This echo will not be printed as the ls command fails\necho \"Execution finished!\"\n\n\n\nThis is used to enable the nounset option which treats references to unset variables as errors.\n#!/bin/bash\nset -u\n\n# Try to access an undefined variable\necho \"Value of undefined variable: $undefined_variable\"\n\n# This echo will not be printed after the undefined variable\necho \"Execution finished!\"\n\n\n\nThis is used to enable the pipefail option, causing a pipeline to return a non-zero exit status if any component fails.\n#!/bin/bash\nset -o pipefail\n\n# Pipe the output of grep from a non-existant file to the sort command\ngrep \"ABCDEFG\" fake_file.txt | sort\n\n# This will return a non-exit status of 2 \necho $?\n\n# This echo will be printed after the non-zero exit status because we haven't run the errexit option\n# Replace set -o pipefail with set -eo pipefail to stop echo command running\necho \"Execution finished!\"\n\n\n\n\nEcho is a very simple solution for doublechecking the output of variables and the results of commands run within your scripts to confirm everything is as it should be:\n#!/bin/bash\n\necho \"This is the start of the script\" \n\nvariable_A=hello\nvariable_B=world\n\necho variable_A is $variable_A\necho variable_B is $variable_B\n\necho doing something with $variable_A and $variable_B here\n\necho \"This is the end of the script\"\n\n\n\nAnother nice set command we can use is to enable debugging mode with set -x. This will print each line of your script to the terminal as it is executed. It can be helpful in identifying where errors are occurring and if variables are correctly defined:\n#!/bin/bash\nset -x\n\n# Define some variables\nfoo=\"hello\"\nbar=\"world\"\n\n# Concatenate variables and print the result\nresult=\"$foo $bar\"\necho \"Result: $result\"\n\n# Do some maths\nnum1=10\nnum2=5\nsum=$((num1 + num2))\necho \"Sum: $sum\"\n\n# Access an undefined variable (intentional error)\necho \"Undefined variable: $undefined_var\"\n\n# End debugging mode\nset +x\n\n# Additional commands that won't be debugged\necho \"Script execution completed.\"\nYou can also run your script with bash -x script.sh without using set -x within the script. It does the same thing.\n\n\n\nIf you’re feeling particularly cautious, this fancy trap command allows you to confirm every line of a script before it runs:\ntrap '(read -p \"[$BASH_SOURCE:$LINENO] $BASH_COMMAND\")' DEBUG\nRun it for our echo script above:\n#!/bin/bash\ntrap '(read -p \"[$BASH_SOURCE:$LINENO] $BASH_COMMAND\")' DEBUG\n\n# Define some variables\nfoo=\"hello\"\nbar=\"world\"\n\n# Concatenate variables and print the result\nresult=\"$foo $bar\"\necho \"Result: $result\"\n\n# Do some maths\nnum1=10\nnum2=5\nsum=$((num1 + num2))\necho \"Sum: $sum\"\n\n# Additional commands that won't be debugged\necho \"Script execution completed.\"\nHit enter to run each line.\n\n\n\nThe die() function can be used to print an error message and terminate a script’s execution. It takes one or more arguments and prints output to stderr:\n#!/bin/bash\n\n# Print error message if no inputs provided at execution\ndie() {\n    local message=$1\n    local error_file=$2\n\n    # Print error message to stderr\n    echo $message &gt;&2\n\n    # If an error file is specified, write the error message to the file\n    if [ -n \"$error_file\" ]; then\n        echo $message &gt; $error_file\n        echo Check error.log\n    fi\n\n    # Exit the script with a status code of 1\n    exit 1\n}\n\n# Example usage of the die function\nif [ $# -eq 0 ]; then\n    die \"Usage: $0 &lt;filename&gt; error.log\"\n    echo Check error.log\nfi\n\n\n\n\nNiko Heikkila’s Don’t use bash for scripting (all the time)\nIntermediate bash scripting\nHow to exit when errors occur in bash\nBest practices for scientific computing\nSome useful shell exit codes explained\nJulia Evans’ Bite Size Bash! zine"
  },
  {
    "objectID": "blog/bash.html#tough-love",
    "href": "blog/bash.html#tough-love",
    "title": "Bash essentials: debugging",
    "section": "",
    "text": "Let’s force bash to behave in a way that eliminates the chances of some subtle bugs from the outset by starting our script with:\n#!/bin/bash\nset -eou pipefail\nYou can use set to change the behaviour of the shell and control script execution. By incorporating this set directive above, you’re doing the following:\n\nset -e mandates immediate script termination upon any command failure\nset -u treats references to undefined variables as errors which helps minimise the likelihood of subtle bugs caused by inadvertent variable omission\nset -o pipefail ensures pipeline errors aren’t masked. If any command in a pipeline fails,\n\nRun the scripts below as is, and then with set commands hashed out. Note the execution of the echo command after the failed commands with/without set.\n\n\nThis enables the errexit option which causes the shell to fail if a command returns a non-zero exit status.\n#!/bin/bash\nset -e\n\n# List the contents of a directory that doesn't exist\nls fake_directory\n\n# This echo will not be printed as the ls command fails\necho \"Execution finished!\"\n\n\n\nThis is used to enable the nounset option which treats references to unset variables as errors.\n#!/bin/bash\nset -u\n\n# Try to access an undefined variable\necho \"Value of undefined variable: $undefined_variable\"\n\n# This echo will not be printed after the undefined variable\necho \"Execution finished!\"\n\n\n\nThis is used to enable the pipefail option, causing a pipeline to return a non-zero exit status if any component fails.\n#!/bin/bash\nset -o pipefail\n\n# Pipe the output of grep from a non-existant file to the sort command\ngrep \"ABCDEFG\" fake_file.txt | sort\n\n# This will return a non-exit status of 2 \necho $?\n\n# This echo will be printed after the non-zero exit status because we haven't run the errexit option\n# Replace set -o pipefail with set -eo pipefail to stop echo command running\necho \"Execution finished!\""
  },
  {
    "objectID": "blog/bash.html#beautiful-echo",
    "href": "blog/bash.html#beautiful-echo",
    "title": "Bash essentials: debugging",
    "section": "",
    "text": "Echo is a very simple solution for doublechecking the output of variables and the results of commands run within your scripts to confirm everything is as it should be:\n#!/bin/bash\n\necho \"This is the start of the script\" \n\nvariable_A=hello\nvariable_B=world\n\necho variable_A is $variable_A\necho variable_B is $variable_B\n\necho doing something with $variable_A and $variable_B here\n\necho \"This is the end of the script\""
  },
  {
    "objectID": "blog/bash.html#the-hero",
    "href": "blog/bash.html#the-hero",
    "title": "Bash essentials: debugging",
    "section": "",
    "text": "Another nice set command we can use is to enable debugging mode with set -x. This will print each line of your script to the terminal as it is executed. It can be helpful in identifying where errors are occurring and if variables are correctly defined:\n#!/bin/bash\nset -x\n\n# Define some variables\nfoo=\"hello\"\nbar=\"world\"\n\n# Concatenate variables and print the result\nresult=\"$foo $bar\"\necho \"Result: $result\"\n\n# Do some maths\nnum1=10\nnum2=5\nsum=$((num1 + num2))\necho \"Sum: $sum\"\n\n# Access an undefined variable (intentional error)\necho \"Undefined variable: $undefined_var\"\n\n# End debugging mode\nset +x\n\n# Additional commands that won't be debugged\necho \"Script execution completed.\"\nYou can also run your script with bash -x script.sh without using set -x within the script. It does the same thing."
  },
  {
    "objectID": "blog/bash.html#one-step-at-a-time",
    "href": "blog/bash.html#one-step-at-a-time",
    "title": "Bash essentials: debugging",
    "section": "",
    "text": "If you’re feeling particularly cautious, this fancy trap command allows you to confirm every line of a script before it runs:\ntrap '(read -p \"[$BASH_SOURCE:$LINENO] $BASH_COMMAND\")' DEBUG\nRun it for our echo script above:\n#!/bin/bash\ntrap '(read -p \"[$BASH_SOURCE:$LINENO] $BASH_COMMAND\")' DEBUG\n\n# Define some variables\nfoo=\"hello\"\nbar=\"world\"\n\n# Concatenate variables and print the result\nresult=\"$foo $bar\"\necho \"Result: $result\"\n\n# Do some maths\nnum1=10\nnum2=5\nsum=$((num1 + num2))\necho \"Sum: $sum\"\n\n# Additional commands that won't be debugged\necho \"Script execution completed.\"\nHit enter to run each line."
  },
  {
    "objectID": "blog/bash.html#the-final-word",
    "href": "blog/bash.html#the-final-word",
    "title": "Bash essentials: debugging",
    "section": "",
    "text": "The die() function can be used to print an error message and terminate a script’s execution. It takes one or more arguments and prints output to stderr:\n#!/bin/bash\n\n# Print error message if no inputs provided at execution\ndie() {\n    local message=$1\n    local error_file=$2\n\n    # Print error message to stderr\n    echo $message &gt;&2\n\n    # If an error file is specified, write the error message to the file\n    if [ -n \"$error_file\" ]; then\n        echo $message &gt; $error_file\n        echo Check error.log\n    fi\n\n    # Exit the script with a status code of 1\n    exit 1\n}\n\n# Example usage of the die function\nif [ $# -eq 0 ]; then\n    die \"Usage: $0 &lt;filename&gt; error.log\"\n    echo Check error.log\nfi"
  },
  {
    "objectID": "blog/bash.html#resources",
    "href": "blog/bash.html#resources",
    "title": "Bash essentials: debugging",
    "section": "",
    "text": "Niko Heikkila’s Don’t use bash for scripting (all the time)\nIntermediate bash scripting\nHow to exit when errors occur in bash\nBest practices for scientific computing\nSome useful shell exit codes explained\nJulia Evans’ Bite Size Bash! zine"
  },
  {
    "objectID": "projects/nextflow.html",
    "href": "projects/nextflow.html",
    "title": "Flattening the Nextflow learning curve",
    "section": "",
    "text": "Workflow frameworks, like Nextflow, have recently emerged as solutions to the challenges posed by bioinformatics pipelines. Bioinformatics data processing typically comprises many individual steps that accept and output varying file formats, and require the use of multiple coding languages and pieces of software. While Nextflow offers a nice solution for creating reproducible, portable workflows that are easy to run, it comes at the cost of a steep learning curve. Nextflow’s users need to learn yet another Domain-Specific Language (DSL) and a new and foreign programming paradigm in order to get the most out of it.\nAs a part of the Australian BioCommons Bring Your Own Data platforms project, we focused on Nextflow over other workflow frameworks in our workflow development activities, developer support, and training programme due to its growing popularity in the community. The outcomes of this work includes:\n\nMy participation in round 3 of the nf-core mentorship programme\nThe development of institutional configuration files for Australian national HPC infrastructure (Gadi, Setonix, Nimbus)\nThe delivery of a national online workshop focused on customising nf-core workflows in partnership with Seqera Labs\nThe development of a simple Nextflow workflow template\nThe ongoing development of an automated configuration builder tool"
  },
  {
    "objectID": "projects/cancer.html",
    "href": "projects/cancer.html",
    "title": "Precision diagnostics in thyroid cancer",
    "section": "",
    "text": "Whole-genome profiling of somatic mutations allows researchers to develop new insights into the underlying causes of cancers and develop new treatments and prevention strategies. However, genetic profiling of poorly understood cancers can be challenging due to the complexity and heterogeneity of somatic mutations across patient populations, and lacking population-level data. Best practice bioinformatics workflows that provide a standardised approach to somatic mutation identification and annotation can address these challenges and provide clinicians with viable treatment targets.\n\nMy role\n\nIdentified and implemented best practice bioinformatic tools and public datasets\nImplemented 2 best pratice workflows to provide patient reports and identify short and structural variants in a cohort of thyroid cancer patients\nIdentified candidate genes for poorly differentiated thyroid cancer\n\n\n\nOutcomes\n\nWorkflow under development\nResults under embargo"
  },
  {
    "objectID": "projects/wildcats.html",
    "href": "projects/wildcats.html",
    "title": "Cross-species applications of genomic tools",
    "section": "",
    "text": "While genomics has enabled vast improvements in the quantification of genome-wide diversity and the identification of adaptive and deleterious alleles in model species, wildlife species have not reaped the same benefits. In resource constrained species, alternative genomic approaches that reduce costs and computational resources can be used to inform conservation management. In the absence of species-specific reference genomes, the availability of a reference genome from a closely related species can provide a reliable substrate for performing variant discovery. Domestic cats benefit from high-quality reference genome assemblies and share a high degree of genomic synteny with their wild counterparts. In this project, I evaluated and demonstrated the value of cross-species application of various genomic resources developed for the domesitc cat in the Sumatran tiger, snow leopard and cheetah.\n\nMy role\n\nConceptualised all aspects of the research for this project\nLiased with veterinarians and zoo managers to collect samples\nExtracted genomic DNA from whole blood and buccal swabs\nProcessed and analysed whole genome sequencing data\nPerformed in silico simulation of genotyping array and reduced representation sequencing datasets\nPerformed and published a literature review and original manuscript\n\n\n\nOutcomes\n\nPublication: Exploiting genomic synteny in Felidae: cross-species genome alignments and SNV discovery can aid conservation management\nOther results currently under embargo"
  },
  {
    "objectID": "projects/110dogs.html",
    "href": "projects/110dogs.html",
    "title": "Canine health and population genomics",
    "section": "",
    "text": "This project involved the processing of a large whole genome sequence dataset comprising 113 samples. To process these samples, we developed and applied two highly scalable workflows to realign all samples to a more recent version of the canine reference genome assembly and call short variants (SNVs and indels) across the genome. The scale of the dataset required the use of the National Computational Infrastructure’s Gadi high performance computer.\n\nMy role\n\nDeveloped and integrated processes for non-human samples into an existing public workflow\nRealigned and called short variants at NCI Gadi\nGenerated a large-scale multi-breed database of short variants\nOnboarded and supported researcher in accessing and using NCI Gadi HPC\n\n\n\nOutcomes\n\nPublication: GWAS for Chronic Superficial Keratitis in the Australian Racing Greyhound\nPublication: De-novo and genome-wide meta-analyses identify a risk haplotype for congenital sensorineural deafness in Dalmatian dogs"
  },
  {
    "objectID": "projects/structuralV.html",
    "href": "projects/structuralV.html",
    "title": "Genomic resources for rare peripheral neuropathies",
    "section": "",
    "text": "Like many other rare and heritable conditions, mapping the causative genetic loci of peripheral neuropathies can be challenging due to a lack of available population-level data and standardised methodologies available to the research community. I have worked closely and collaboratively with the Australian motor neuropathies community to develop reproducible and sensitive protocols for identifying clinically relevant genomic events in patient cohorts and families.\n\nMy role\n\nDesign and implement a protocol for filtering variants under expected modes of inheritance\nDesign and implement a public, sensitive, and reproducible workflow for identifying and annotating structural variation\nIdentify candidate causative genomic events\nLiase and collaborate with bioinformaticians, clinicians, and geneticists to optimise a bioinformatics workflow\n\n\n\nOutcomes\n\nWorkflow: GermlineStructuralV-nf\nResults currently under embargo"
  },
  {
    "objectID": "projects/bioimage.html",
    "href": "projects/bioimage.html",
    "title": "Public cloud image for bioinformatics",
    "section": "",
    "text": "For most bioinformatics applications, working at the command-line interface is unavoidable and empowering. The CLI gives users the power to work more efficiently, use scalable computing resources, and work more reproducibly. Learning how to effectively use the CLI environment can be particilarly challenging for life scienctists who don’t receive any formal computer science training.\nTo address the challenges of set up and installation, I worked in partnership with Pawsey Supercomputing Research Center and the National Computational Infrastructure to create a purpose built cloud environment to help researchers working on the command-line. It is called the BioImage and is currently available on Pawsey’s Nimbus cloud platform. We are currently working on making it available on other public research cloud and commercial cloud platforms."
  },
  {
    "objectID": "projects/burmese.html",
    "href": "projects/burmese.html",
    "title": "Feline models of complex human disease",
    "section": "",
    "text": "Cat breeds can serve as informative natural genetic models of human disease because of their similarity to humans in terms of genetics, anatomy, physiology, and our shared environment. By studying cat breeds with a high prevalence of a hertiable disease, like feline diabetes mellitus (FDM) in Burmese cats, we can gain insights into the underlying genetic mechanisms of the diseases.\nFor this project, we explored the genetic landscape of FDM in a population of Australian and European Burmese cats. We used multiple techniques and technologies to identify regions of disease association and selection in affected cats.\n\nMy role\n\nConceptualised all aspects of the research for this project\nLiased with veterinarians and breeders to collect samples\nExtracted genomic DNA from whole blood and buccal swabs\nProcessed and analysed Illumina genotyping array and whole genome sequencing data\nIdentified candidate genes and variants for FDM\nPerformed and published a literature review and original manuscript\n\n\n\nOutcomes\n\nWorkflow: Probe Remap workflow\nPublication: The Burmese cat as a genetic model of type 2 diabetes in humans\nPublication: Mapping the genetic basis of diabetes mellitus in the Australian Burmese cat (Felis catus)"
  },
  {
    "objectID": "projects/hpc.html",
    "href": "projects/hpc.html",
    "title": "Bioinformatics and HPC training",
    "section": "",
    "text": "Bioinformaticians and life scientists are increasingly turning to high performance computing infrastructure and efficient, scalable workflows as their research becomes more data intensive. Accessing and getting the most out of these facilities can be challenging for many of us who have never received formal computational sciences training. This webinar series I designed and delivered with colleagues across national computational infrastructure providers introduces the high-performance computing facilities and services available to Australian researchers and ways to access and use them to do high impact research.\n\nWebinar: Pro tips for scaling bioinformatics workflows for HPC\nWebinar: Where to go when your bioinformatics runs out of compute\nWebinar: High performance bioinformatics: submitting your best NCMAS application\nWebinar: Getting started with mapping and variant calling on the command line"
  },
  {
    "objectID": "projects/parabricks.html",
    "href": "projects/parabricks.html",
    "title": "Evaluating optimised genomics workflows",
    "section": "",
    "text": "Genomics-based research is computationally intensive work and we are generating data faster and at a higher scale than ever before. Accelerated computing using specialised hardware is key to addressing these intensive data loads.\nI worked closely with partners from the National Computational Infrastructure (NCI), who were looking to make scalable bioinformatics data processing more accessible at their facilities. We worked with NCI to evaluate the performance of NVIDIA Parabricks software suite at their Gadi HPC and benchmark it against highly optimised CPU-based workflows. GPU-accelerated tools, like Parabricks, are currently rare in bioinformatics but have the capacity to significantly reduce the time and computational resources required for complex data processing like mapping and variant calling. The outcomes of this work includes:\n\nA public biological validation performance evaluation protocol\nA public report summarising our findings\nThe availability of NVIDIA Parabricks license at NCI Gadi HPC"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Georgie Samaha",
    "section": "",
    "text": "I’m a community-focused bioinformatician, working on making bioinformatics more approachable for all life scientists. I’m the Bioinformatics Group Lead at the Sydney Informatics Hub, University of Sydney, working with Australian BioCommons."
  },
  {
    "objectID": "blog/fastq.html",
    "href": "blog/fastq.html",
    "title": "File formats in bioinformatics: FASTQ",
    "section": "",
    "text": "Learn from my mistakes\n\n\n\nI’ve made lots of mistakes in my time doing bioinformatics, many of them have come down to rushing into analysis without fully understanding the file formats I was working with.\n\n\nThere are many and varied file formats in bioinformatics. Many of them are text-based and can technically be opened in a text editor but are often so large they cannot be opened without crashing your machine. Other file types are binary and cannot be opened in a text editor at all. These days, most tools will handle standard file formats but sometimes you will need to do some manual manipulation to get your data into the right format for a particular tool.\nHere, I explain some common file formats and things to consider when working with them. These things are very easy to forget unless you’re working with these file regularly. Others have explained this better than I can, so I will link to other resources where possible.\n\n\nFASTQ is the current default file format for raw sequencing reads (e.g. from Illumina, Nanopore, or PacBio instruments) storage. Unlike FASTA, which stores only sequences and headers, FASTQ also stores per-base quality scores, which makes it essential for almost every downstream analysis.\n\n\nEach sequencing read in a FASTQ file is represented by four lines:\n\nHeader line starting with @: contains the read identifier and sometimes instrument metadata.\n\nSequence line: the raw nucleotide sequence (A, C, G, T, N).\n\nSeparator line starting with +: sometimes repeats the header, but often just a +.\n\nQuality score line: encodes per-base sequencing quality, using ASCII characters.\n\nConsider this example:\n@SEQ_ID\nGATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATCCATTTGTTCAACTCACAGTTT\n+\n!''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF&gt;&gt;&gt;&gt;&gt;&gt;CCCCCCC65\nYou’ll often see FASTQ files named .fastq, .fq, .fq.gz, or .fastq.gz.\n\n\n\n\n\n\n\n\nExtension\nTypical usage\nExample source\n\n\n\n\n.fastq\nMost common extension\nIllumina NextSeq, HiSeq, NovaSeq data\n\n\n.fq\nShort form, used interchangeably\nSome SRA/ENA downloads\n\n\n.fastq.gz or .fq.gz\nFASTQ compressed with gzip\nNCBI SRA, ENA, institutional sequencing facilities\n\n\n\nFASTQ files can contain one or many read sequences and are often paired. Sequencing can be run in single-end or paired-end mode. This choice affects how many FASTQ files you receive and how you use them. These days, paired-end sequencing is most common for short and long read technologies. In paired-end sequencing, each DNA fragment is sequenced from both ends, producing two reads per fragment. These reads are stored in separate FASTQ files, often named with _R1 for forward reads and _R2 for reverse reads to indicate the first and second reads of each pair.\n\n\n\n\n\n\nKeep pairs in sync\n\n\n\nIf you split, shuffle, or filter one FASTQ file without doing the same to its pair, you’ll break pairing. Many tools will fail outright if R1 and R2 files are out of sync. Those that don’t will give incorrect results. Pairs of FASTQ files represent the same biological sample, they are not replicates.\n\n\n\n\n\n\n\n\nMultiple files per pair\n\n\n\nYou may be working with more than 2 FASTQ files per sample. This happens when:\n\nMultiple flowcell lanes are used by the sequencer e.g. on older Illumunia HiSeq machines where flowcells are processed separately. Splitting samples across lanes was performed to reduce technical (lane) bias.\n\nsample_S1_L001_R1_001.fastq.gz\nsample_S1_L002_R1_001.fastq.gz\nsample_S1_L001_R2_001.fastq.gz\nsample_S1_L002_R2_001.fastq.gz\n\nFile sizes need to be managed because they’re so big: if you’ve chosen to sequence a large genome at a very high depth, you may end up with multiple FASTQ files to better manage the gigabytes data.\n\nsample_R1_001.fastq.gz\nsample_R1_002.fastq.gz\nsample_R2_001.fastq.gz\nsample_R2_002.fastq.gz\n\nSeuqencing across multiple runs to increase depth or because of failed runs. These filenames will often include a flowcell ID and you’ll have multiple R1/R2 pairs associated with a different flowcell ID.\n\nsample_S1_L001_R1_001.fastq.gz \nsample_S1_L001_R2_001.fastq.gz\nsample_S1_L002_R1_002.fastq.gz \nsample_S1_L002_R2_002.fastq.gz\n\n\n\n\nSequencing platforms output FASTQ files, but the content and conventions differ depending on the technology. The differences mainly come from read length, quality encoding, and the information included in headers.\n\nPacBio FASTQ convetions\nOxford Nanopore FASTQ convetions\nIllumina FASTQ convetions\n\n\n\n\n\n\n\n\n\n\n\n\nPlatform\nRead length\nHeader style / metadata\nQuality scores\nCommon uses\nFile naming\n\n\n\n\nIllumina\n50–300 bp (paired-end)\nCompact IDs: instrument, run, flowcell, lane, tile, x/y, read number (R1/R2)\nVery high (Q30+), Phred+33\nVariant calling, RNAseq, ChIP-seq, metagenomics\nR1/R2 pairs; often split by lane (L001, L002) or chunks (_001, _002)\n\n\nPacBio\n10–25 kb HiFi; up to 100 kb subreads\nMovie name, ZMW number, start–end positions\nConsensus accuracy, Q20–Q30 (Phred+33)\nDe novo assembly, structural variants, isoform discovery\nOne FASTQ per SMRT cell\n\n\nONT\nHighly variable: 500 bp – &gt;1 Mb\nRich metadata: UUID, run ID, sample ID, channel, start time\nLower on average, Phred+33; error profile dominated by indels\nReal-time sequencing, metagenomics, ultra-long reads, structural variants\nMany small FASTQs, often merged before analysis\n\n\n\n\n\n\n\nFASTQ files can represent many different types of sequencing data across different types of biological material and experimental designs.\n1. DNA sequencing\n- Whole-genome sequencing (WGS): FASTQs contain DNA reads covering the entire genome. Used for variant discovery, structural variation, genome assembly, and genome resequencing\n- Whole-exome sequencing (WES): FASTQs contain only reads mapping to captured exons. Used for detecting variants in coding regions\n- Targeted panels: FASTQs may contain reads from specific genes or loci (e.g. cancer gene panels, microbial typing assays)\n2. RNA sequencing\n- Bulk RNAseq: FASTQs contain cDNA reads derived from mRNA, representing gene expression levels across a population of cells\n- Single-cell RNAseq: FASTQs also encode barcodes and UMIs in read structures, linking reads back to individual cells and molecules\n- Long-read RNA-seq (Iso-Seq, ONT direct RNA): FASTQs may contain full-length transcript reads, used for isoform discovery and splicing analysis\n- Small RNA-seq: FASTQs contain very short reads (18–30 nt) from miRNAs, siRNAs, etc., used for regulatory RNA studies\n3. Metagenomic sequencing\n- FASTQs may contain DNA or RNA reads from complex microbial communities\n- Used for profiling community composition, functional gene annotations, or metagenome assembly\n- Common in microbiome studies, pathogen detection, and environmental sequencing\n- Amplicon sequencing (16S rRNA): FASTQs with targeted PCR products\n4. Epigenomics\n- ChIP-seq/ATAC-seq: DNA FASTQs representing protein-bound DNA fragments or accessible chromatin regions\n- Bisulfite sequencing: DNA FASTQs encoding methylation patterns through chemical conversion.\n\n\n\nI strongly recommend using dedicated tools such as fastp or seqtk to manipulate and query FASTQ files.\n\n\n\n\nFASTQ wiki\nIUPAC codes for nucleotides and amino acids\nPaired-end vs single-end short-read sequencing\nPacBio FASTQ convetions\nOxford Nanopore FASTQ convetions\nIllumina FASTQ convetions"
  },
  {
    "objectID": "blog/fastq.html#fastq",
    "href": "blog/fastq.html#fastq",
    "title": "File formats in bioinformatics: FASTQ",
    "section": "",
    "text": "FASTQ is the current default file format for raw sequencing reads (e.g. from Illumina, Nanopore, or PacBio instruments) storage. Unlike FASTA, which stores only sequences and headers, FASTQ also stores per-base quality scores, which makes it essential for almost every downstream analysis.\n\n\nEach sequencing read in a FASTQ file is represented by four lines:\n\nHeader line starting with @: contains the read identifier and sometimes instrument metadata.\n\nSequence line: the raw nucleotide sequence (A, C, G, T, N).\n\nSeparator line starting with +: sometimes repeats the header, but often just a +.\n\nQuality score line: encodes per-base sequencing quality, using ASCII characters.\n\nConsider this example:\n@SEQ_ID\nGATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATCCATTTGTTCAACTCACAGTTT\n+\n!''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF&gt;&gt;&gt;&gt;&gt;&gt;CCCCCCC65\nYou’ll often see FASTQ files named .fastq, .fq, .fq.gz, or .fastq.gz.\n\n\n\n\n\n\n\n\nExtension\nTypical usage\nExample source\n\n\n\n\n.fastq\nMost common extension\nIllumina NextSeq, HiSeq, NovaSeq data\n\n\n.fq\nShort form, used interchangeably\nSome SRA/ENA downloads\n\n\n.fastq.gz or .fq.gz\nFASTQ compressed with gzip\nNCBI SRA, ENA, institutional sequencing facilities\n\n\n\nFASTQ files can contain one or many read sequences and are often paired. Sequencing can be run in single-end or paired-end mode. This choice affects how many FASTQ files you receive and how you use them. These days, paired-end sequencing is most common for short and long read technologies. In paired-end sequencing, each DNA fragment is sequenced from both ends, producing two reads per fragment. These reads are stored in separate FASTQ files, often named with _R1 for forward reads and _R2 for reverse reads to indicate the first and second reads of each pair.\n\n\n\n\n\n\nKeep pairs in sync\n\n\n\nIf you split, shuffle, or filter one FASTQ file without doing the same to its pair, you’ll break pairing. Many tools will fail outright if R1 and R2 files are out of sync. Those that don’t will give incorrect results. Pairs of FASTQ files represent the same biological sample, they are not replicates.\n\n\n\n\n\n\n\n\nMultiple files per pair\n\n\n\nYou may be working with more than 2 FASTQ files per sample. This happens when:\n\nMultiple flowcell lanes are used by the sequencer e.g. on older Illumunia HiSeq machines where flowcells are processed separately. Splitting samples across lanes was performed to reduce technical (lane) bias.\n\nsample_S1_L001_R1_001.fastq.gz\nsample_S1_L002_R1_001.fastq.gz\nsample_S1_L001_R2_001.fastq.gz\nsample_S1_L002_R2_001.fastq.gz\n\nFile sizes need to be managed because they’re so big: if you’ve chosen to sequence a large genome at a very high depth, you may end up with multiple FASTQ files to better manage the gigabytes data.\n\nsample_R1_001.fastq.gz\nsample_R1_002.fastq.gz\nsample_R2_001.fastq.gz\nsample_R2_002.fastq.gz\n\nSeuqencing across multiple runs to increase depth or because of failed runs. These filenames will often include a flowcell ID and you’ll have multiple R1/R2 pairs associated with a different flowcell ID.\n\nsample_S1_L001_R1_001.fastq.gz \nsample_S1_L001_R2_001.fastq.gz\nsample_S1_L002_R1_002.fastq.gz \nsample_S1_L002_R2_002.fastq.gz\n\n\n\n\nSequencing platforms output FASTQ files, but the content and conventions differ depending on the technology. The differences mainly come from read length, quality encoding, and the information included in headers.\n\nPacBio FASTQ convetions\nOxford Nanopore FASTQ convetions\nIllumina FASTQ convetions\n\n\n\n\n\n\n\n\n\n\n\n\nPlatform\nRead length\nHeader style / metadata\nQuality scores\nCommon uses\nFile naming\n\n\n\n\nIllumina\n50–300 bp (paired-end)\nCompact IDs: instrument, run, flowcell, lane, tile, x/y, read number (R1/R2)\nVery high (Q30+), Phred+33\nVariant calling, RNAseq, ChIP-seq, metagenomics\nR1/R2 pairs; often split by lane (L001, L002) or chunks (_001, _002)\n\n\nPacBio\n10–25 kb HiFi; up to 100 kb subreads\nMovie name, ZMW number, start–end positions\nConsensus accuracy, Q20–Q30 (Phred+33)\nDe novo assembly, structural variants, isoform discovery\nOne FASTQ per SMRT cell\n\n\nONT\nHighly variable: 500 bp – &gt;1 Mb\nRich metadata: UUID, run ID, sample ID, channel, start time\nLower on average, Phred+33; error profile dominated by indels\nReal-time sequencing, metagenomics, ultra-long reads, structural variants\nMany small FASTQs, often merged before analysis\n\n\n\n\n\n\n\nFASTQ files can represent many different types of sequencing data across different types of biological material and experimental designs.\n1. DNA sequencing\n- Whole-genome sequencing (WGS): FASTQs contain DNA reads covering the entire genome. Used for variant discovery, structural variation, genome assembly, and genome resequencing\n- Whole-exome sequencing (WES): FASTQs contain only reads mapping to captured exons. Used for detecting variants in coding regions\n- Targeted panels: FASTQs may contain reads from specific genes or loci (e.g. cancer gene panels, microbial typing assays)\n2. RNA sequencing\n- Bulk RNAseq: FASTQs contain cDNA reads derived from mRNA, representing gene expression levels across a population of cells\n- Single-cell RNAseq: FASTQs also encode barcodes and UMIs in read structures, linking reads back to individual cells and molecules\n- Long-read RNA-seq (Iso-Seq, ONT direct RNA): FASTQs may contain full-length transcript reads, used for isoform discovery and splicing analysis\n- Small RNA-seq: FASTQs contain very short reads (18–30 nt) from miRNAs, siRNAs, etc., used for regulatory RNA studies\n3. Metagenomic sequencing\n- FASTQs may contain DNA or RNA reads from complex microbial communities\n- Used for profiling community composition, functional gene annotations, or metagenome assembly\n- Common in microbiome studies, pathogen detection, and environmental sequencing\n- Amplicon sequencing (16S rRNA): FASTQs with targeted PCR products\n4. Epigenomics\n- ChIP-seq/ATAC-seq: DNA FASTQs representing protein-bound DNA fragments or accessible chromatin regions\n- Bisulfite sequencing: DNA FASTQs encoding methylation patterns through chemical conversion.\n\n\n\nI strongly recommend using dedicated tools such as fastp or seqtk to manipulate and query FASTQ files.\n\n\n\n\nFASTQ wiki\nIUPAC codes for nucleotides and amino acids\nPaired-end vs single-end short-read sequencing\nPacBio FASTQ convetions\nOxford Nanopore FASTQ convetions\nIllumina FASTQ convetions"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Georgie Samaha",
    "section": "",
    "text": "I work at the Sydney Informatics Hub, University of Sydney, and Australian BioCommons, directly supporting Australian researchers by developing open-source tools and solutions and consulting on reproducible research practices and best-practice bioinformatics.\nI am the product owner for the Australian BioCommons’ BioCLI and University of Sydney’s Sydney Research Cloud projects. My interest lies in making computing infrastructure and bioinformatics methods more approachable, particularly for life scientists who are new to compute-based research.\nI completed a PhD in mammalian genomics under the supervision of Associate Professor Bianca Waud and Professor Claire Wade. My research focused on applying genomic technologies to understand the genetic basis of complex traits in wild felids and domestic cats."
  }
]